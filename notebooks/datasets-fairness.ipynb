{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54064acb-3fd0-400b-ad48-1aefc88975af",
   "metadata": {},
   "source": [
    "# Fairness in binary classification [draft]\n",
    "\n",
    "Study and reproductibility of the paper:\n",
    "[Leveraging Labeled and Unlabeled data for consistent fair binary classification](https://proceedings.neurips.cc/paper_files/paper/2019/file/ba51e6158bcaf80fd0d834950251e693-Paper.pdf)\n",
    "\n",
    "\n",
    "Other references:\n",
    "\n",
    "- [Fairness Beyond Disparate Treatment & Disparate Impact, Zafar & al (2017)](https://arxiv.org/abs/1610.08452)\n",
    "\n",
    "- [Equal Opportunity in Supervised Learning, Hardt & al (2016)](https://arxiv.org/abs/1610.02413)\n",
    "\n",
    "- [Empirical Risk Minimization under Fairness Constraints, Donini & al (2020)](https://arxiv.org/abs/1802.08626)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32d9b1d6-319f-4fca-a919-df4cea60d8f3",
   "metadata": {},
   "source": [
    "## Loading libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92b5111f-007e-4499-9f1f-dc1c375d062c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e861d64-6f2f-4073-967c-2a7d4cbd7f13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fairness.utils import *\n",
    "from fairness.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "448f08e8-7152-41b7-93ed-3aae234ad01d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "from itertools import product"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92afd246-2d0d-499a-a81d-52ba60f6c0c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Estimating results from standard models\n",
    "\n",
    "Expected output:\n",
    "\n",
    "<img src='paper_results.png' width=70% height=70%>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2f05bb7-6e5c-429a-ab19-53af5a51d185",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "C_span = np.logspace(-2, 4, 30)\n",
    "\n",
    "lin_params = np.asarray([{'C': c} for c in C_span])\n",
    "rbf_params = np.asarray([{'C':x, 'gamma': y} for x, y in product(C_span, [1e-3, 1e-2, 1e-1, 1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70b5602d-04e0-4d1c-ad44-98ee30cc667c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DataConfig = namedtuple('DataConfig', 'name load loader_kwargs subsample sample_proportion')\n",
    "ModelConfig = namedtuple('ModelConfig', 'name need_cv Model model_kwargs cv_config')\n",
    "\n",
    "data_configs = [\n",
    "    # name, function, kwargs, subsample_training, subsampling proportion\n",
    "    DataConfig('Adult', load_adult_data, dict(onehot=False), True, 1),\n",
    "    # DataConfig('Arrythmia', load_arrhythmia_data, dict(), True, 1),\n",
    "    # DataConfig('Drug', load_drug_data, dict(standardize=False), True, 1),\n",
    "    # DataConfig('German', load_german_data, dict(onehot=False, standardize=False), True, 1)\n",
    "]\n",
    "\n",
    "model_configs = [\n",
    "    # name, need_cross_val, model_function, model_kwargs, cv_kwargs\n",
    "    ModelConfig('Lin.LR', False, LogisticRegression, dict(max_iter=2000, penalty='l2'), lin_params),\n",
    "    # ModelConfig('Lin.SVM', True, SVC, dict(kernel='linear', probability=True), lin_params),\n",
    "    # ModelConfig('SVM', True, SVC, dict(kernel='rbf', probability=True), rbf_params),\n",
    "    # ModelConfig('RF', True, RandomForestClassifier, dict(n_estimators=500), )\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58cd4c19-d7e1-4777-b088-05c9d38ca8e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nb_iter = 1  #  30\n",
    "scores = ['ACC', 'DEO']\n",
    "datasets = ['Arrythmia', 'Adult', 'German', 'Drug']\n",
    "\n",
    "methods = [\n",
    "    'Lin.SVM', 'Lin.SVM+Ours', 'Lin.LR', 'Lin.LR+Ours', \n",
    "    'SVM', 'SVM+Ours', 'LR', 'LR+Ours', 'RF', 'RF+Ours'\n",
    "]\n",
    "summary = pd.DataFrame(0, index=methods, columns=pd.MultiIndex.from_product([datasets, scores]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afd50426-673e-435f-9d33-8aef2fe07f2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Lin.LR\n",
      "------------------------------------------------------\n",
      "\n",
      "***\n",
      "Processing Adult\n",
      "\n",
      "+--------------+-------------+--------------+\n",
      "| Estimation   | Accuracy    | Unfairness   |\n",
      "+==============+=============+==============+\n",
      "| Original     | 0.84 ± 0.00 | 0.15 ± 0.00  |\n",
      "+--------------+-------------+--------------+\n",
      "| Calibrated   | 0.84 ± 0.00 | 0.05 ± 0.00  |\n",
      "+--------------+-------------+--------------+\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for mc in model_configs:\n",
    "    \n",
    "    print(f'Model: {mc.name}')\n",
    "    print('------------------------------------------------------')\n",
    "    for dc in data_configs:\n",
    "        print('\\n***')\n",
    "        print(f'Processing {dc.name}\\n')\n",
    "\n",
    "        acc = []\n",
    "        deo = []\n",
    "        \n",
    "        calib_acc = []\n",
    "        calib_deo = []\n",
    "        \n",
    "        for i in range(nb_iter):\n",
    "            # Loading and subsampling the data\n",
    "            X, y, Xt, yt, s = dc.load(**dc.loader_kwargs)\n",
    "            \n",
    "            accs = np.zeros(len(mc.cv_config))\n",
    "            deos = np.zeros(len(mc.cv_config))\n",
    "\n",
    "            for j, p in enumerate(mc.cv_config):\n",
    "                print(f'Iteration {i+1}  Param {j+1}', end='\\r')\n",
    "                current_model = mc.Model(**p, **mc.model_kwargs)\n",
    "                test_acc = 0\n",
    "                test_deo = 0\n",
    "                for train, test in folds_generator(X, y, s):\n",
    "                    X_train, y_train = X.iloc[train], y.iloc[train]\n",
    "                    X_test, y_test = X.iloc[test], y.iloc[test]\n",
    "                    current_model.fit(X_train, y_train)\n",
    "                    y_pred = current_model.predict(X_test)\n",
    "                    test_acc += np.mean(y_pred == y_test)\n",
    "                    test_deo += empirical_unfairness(y_test, y_pred, X_test[s])\n",
    "                \n",
    "                accs[j] = test_acc / 10\n",
    "                deos[j] = test_deo / 10\n",
    "    \n",
    "            best_params = get_npv_optimal_params(mc.cv_config, accs, deos, threshold=.99)\n",
    "            model = mc.Model(**best_params, **mc.model_kwargs).fit(X, y)\n",
    "\n",
    "            \n",
    "            y_pred = model.predict(Xt)\n",
    "            y_prob = model.predict_proba(Xt)[:, 1]\n",
    "            \n",
    "            acc.append(np.mean(y_pred == yt))\n",
    "            deo.append(empirical_unfairness(yt, y_pred, Xt[s]))\n",
    "\n",
    "            theta, value, y_calib = recalibrate_predictions(y_prob, Xt[s])\n",
    "            calib_acc.append(np.mean(y_calib == yt))\n",
    "            calib_deo.append(empirical_unfairness(yt, y_calib, Xt[s]))\n",
    "\n",
    "\n",
    "        \n",
    "        acc_avg = np.nanmean(acc)\n",
    "        acc_std = np.nanstd(acc)\n",
    "        \n",
    "        deo_avg = np.nanmean(deo)\n",
    "        deo_std = np.nanstd(deo)\n",
    "\n",
    "        calib_acc_avg = np.nanmean(calib_acc)\n",
    "        calib_acc_std = np.nanstd(calib_acc)\n",
    "        \n",
    "        calib_deo_avg = np.nanmean(calib_deo)\n",
    "        calib_deo_std = np.nanstd(calib_deo)\n",
    "        \n",
    "        summary.loc[mc.name, (dc.name, 'ACC')] = f'{acc_avg:.2f} ± {acc_std:.2f}'\n",
    "        summary.loc[mc.name, (dc.name, 'DEO')] = f'{deo_avg:.2f} ± {deo_std:.2f}'\n",
    "        summary.loc[mc.name+'+Ours', (dc.name, 'ACC')] = f'{calib_acc_avg:.2f} ± {calib_acc_std:.2f}'\n",
    "        summary.loc[mc.name+'+Ours', (dc.name, 'DEO')] = f'{calib_deo_avg:.2f} ± {calib_deo_std:.2f}'\n",
    "       \n",
    "        print(\n",
    "            tabulate(\n",
    "                [\n",
    "                    ['Original', f'{acc_avg:.2f} ± {acc_std:.2f}', f'{deo_avg:.2f} ± {deo_std:.2f}'], \n",
    "                    ['Calibrated', f'{calib_acc_avg:.2f} ± {calib_acc_std:.2f}', f'{calib_deo_avg:.2f} ± {calib_deo_std:.2f}']\n",
    "                ], \n",
    "                headers=['Estimation', 'Accuracy', 'Unfairness'],\n",
    "                tablefmt='grid',\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    print('------------------------------------------------------')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
